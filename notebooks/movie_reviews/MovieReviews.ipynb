{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/perryism/machine_learning_101/master/data/imdb_labelled.txt -O /tmp/imdb.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "[sklearn doc](https://scikit-learn.org/stable/modules/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from lib import is_rotten, predict, plot_confusion_matrix, Sentiment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "reviews = pd.read_csv('/tmp/imdb.csv', sep=\"\\t\", header=None)\n",
    "reviews.columns = ['review', 'like']\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_raw_train, X_raw_test, y_train, y_test = train_test_split(reviews['review'], reviews['like'], test_size=0.33, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore\n",
    "\n",
    "real world problems: not clean, messy, for example, voicebase, transcript not accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "with pd.option_context(\"display.max_rows\", reviews.shape[0]):\n",
    "    display(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "reviews['like'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How would you do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from toolz import curry\n",
    "\n",
    "@curry\n",
    "def is_good(positive_words, review):\n",
    "    lower_quote = review.lower()\n",
    "    for positive_word in positive_words:\n",
    "        if positive_word.lower() in lower_quote:\n",
    "            return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "def predict(df, positive_words):\n",
    "    good_func = is_good(positive_words)\n",
    "    return df.apply(good_func)\n",
    "\n",
    "#try adding 'excellent' to the list\n",
    "positive_words = ['good']\n",
    "\n",
    "y_predict = predict(X_raw_train, positive_words)\n",
    "accuracy_score(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning approach\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO\n",
    "\n",
    "s = Sentiment.demo()\n",
    "s.predict(\"This movie is boring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    " \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "m = vectorizer.fit_transform([\"The quick brown fox jumps over the lazy dog\"]).todense()\n",
    "f = vectorizer.get_feature_names()\n",
    "pd.concat([pd.DataFrame(m), pd.DataFrame(f).T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.transform([\"The fox is in the box\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews['review'])\n",
    "y = reviews['like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Terminologies\n",
    "- X  features\n",
    "\n",
    "- y  labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# LogisticRegression is a classifer. checkout https://en.wikipedia.org/wiki/Logistic_regression for more details\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X)\n",
    "print(accuracy_score(y, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks so good\n",
    "\n",
    "## Can we say our model is very accurate?  \n",
    "\n",
    "## Or is it really? What is wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memorization vs Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_raw_train, X_raw_test, y_train, y_test = train_test_split(reviews['review'], reviews['like'], test_size=0.33, random_state=42)\n",
    "\n",
    "clf.fit(vectorizer.transform(X_raw_train), y_train)\n",
    "y_predict = clf.predict(vectorizer.transform(X_raw_test))\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the right measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(vectorizer.transform(X_raw_test))\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine you are writing a spam filter, and the samples you collected are mostly ham.\n",
    "\n",
    "y_true = [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "# We can have the model ALWAYS returns 0s\n",
    "y_predict = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "print(accuracy_score(y_true, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is precision? What is recall?\n",
    "\n",
    "Image(url= \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 score takes consideration of both precision and recall\n",
    "\n",
    "Image(url=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/057ffc6b4fa80dc1c0e1f2f1f6b598c38cdd7c23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(vectorizer.transform(X_raw_test))\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "print(accuracy_score(y_test, y_predict))\n",
    "print(f1_score(y_test, y_predict))\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "\n",
    "precision/recall trade off\n",
    "\n",
    "eg. if you are writing a parental control filter for children, you probably want high precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "plt.figure(figsize=(10,5))\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "result = pd.DataFrame(np.array([y_predict, y_test]).T, columns=['predict', 'actual'])\n",
    "compare = pd.concat([result, X_raw_test.reset_index()['review']], axis=1)\n",
    "\n",
    "compare.query(\"actual == 1\").head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test it yourself\n",
    "\n",
    "my_review = \"This is so boring.\"\n",
    "Sentiment(vectorizer, clf).predict(my_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word cloud\n",
    "\n",
    "coef = np.array(clf.coef_)\n",
    "positive_idx = np.where( coef > .4 )[1]\n",
    "negative_idx = np.where( coef < -0.4 )[1]\n",
    "features = vectorizer.get_feature_names()\n",
    "\n",
    "#fix me\n",
    "pos_freq = dict(list(map(lambda idx: (features[idx], coef[0,idx]), positive_idx )))\n",
    "neg_freq = dict(list(map(lambda idx: (features[idx], coef[0,idx]), negative_idx )))\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud().generate_from_frequencies(pos_freq)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate_from_frequencies(neg_freq)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
